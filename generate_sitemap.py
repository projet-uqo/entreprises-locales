# -*- coding: utf-8 -*-
"""generate_sitemap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11EDqaavVRfeO6P5m6xAL8u5lo63XHtdx
"""

# Dossier où tes fichiers HTML sont générés
SITE_DIR = "site"
BASE_URL = "https://projet-uqo.github.io/entreprises-locales"  # ⚠️ adapte avec ton dépôt GitHub Pages (lien vers site web)

# Générer sitemap.xml
def generate_sitemap():
    urls = []
    for file in os.listdir(SITE_DIR):
        if file.endswith(".html"):
            loc = f"{BASE_URL}/{file}"
            lastmod = datetime.today().strftime("%Y-%m-%d")
            urls.append(f"""
  <url>
    <loc>{loc}</loc>
    <lastmod>{lastmod}</lastmod>
    <priority>{'1.0' if file == 'index.html' else '0.8'}</priority>
  </url>""")

    sitemap_content = f"""<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
{''.join(urls)}
</urlset>
"""
    with open(os.path.join(SITE_DIR, "sitemap.xml"), "w", encoding="utf-8") as f:
        f.write(sitemap_content)
    print("✅ sitemap.xml généré")

# Générer robots.txt
def generate_robots():
    robots_content = f"""User-agent: *
Allow: /

Sitemap: {BASE_URL}/sitemap.xml
"""
    with open(os.path.join(SITE_DIR, "robots.txt"), "w", encoding="utf-8") as f:
        f.write(robots_content)
    print("✅ robots.txt généré")

if __name__ == "__main__":
    generate_sitemap()
    generate_robots()
